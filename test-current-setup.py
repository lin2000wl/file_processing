#!/usr/bin/env python3
"""
æµ‹è¯•å½“å‰MonkeyOCRè®¾ç½®
"""

import sys
import os
import subprocess

def test_current_setup():
    """æµ‹è¯•å½“å‰è®¾ç½®"""
    print("ğŸ” æµ‹è¯•å½“å‰MonkeyOCRè®¾ç½®...")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ç³»ç»ŸGPUçŠ¶æ€
    print("1. ğŸ–¥ï¸  ç³»ç»ŸGPUçŠ¶æ€:")
    try:
        result = subprocess.run(['lspci', '|', 'grep', '-i', 'vga'], 
                              shell=True, capture_output=True, text=True)
        if result.stdout:
            print(f"   æ˜¾å¡: {result.stdout.strip()}")
        else:
            print("   æ˜¾å¡: æœªæ£€æµ‹åˆ°ä¸“ç”¨æ˜¾å¡")
    except:
        print("   æ˜¾å¡: æ£€æµ‹å¤±è´¥")
    
    # 2. æ£€æŸ¥NVIDIAé©±åŠ¨
    print("\n2. ğŸš€ NVIDIAé©±åŠ¨çŠ¶æ€:")
    try:
        result = subprocess.run(['nvidia-smi'], capture_output=True, text=True)
        if result.returncode == 0:
            print("   âœ… NVIDIAé©±åŠ¨å·²å®‰è£…")
            print(f"   è¾“å‡º: {result.stdout[:200]}...")
        else:
            print("   âŒ NVIDIAé©±åŠ¨æœªå®‰è£…æˆ–ä¸å¯ç”¨")
    except FileNotFoundError:
        print("   âŒ nvidia-smiå‘½ä»¤ä¸å­˜åœ¨")
    
    # 3. æ£€æŸ¥DockerçŠ¶æ€
    print("\n3. ğŸ³ DockerçŠ¶æ€:")
    try:
        result = subprocess.run(['docker', '--version'], capture_output=True, text=True)
        if result.returncode == 0:
            print(f"   âœ… Dockerç‰ˆæœ¬: {result.stdout.strip()}")
        else:
            print("   âŒ Dockerä¸å¯ç”¨")
    except FileNotFoundError:
        print("   âŒ Dockeræœªå®‰è£…")
    
    # 4. æ£€æŸ¥Docker GPUæ”¯æŒ
    print("\n4. ğŸ¯ Docker GPUæ”¯æŒ:")
    try:
        result = subprocess.run(['which', 'nvidia-ctk'], capture_output=True, text=True)
        if result.returncode == 0:
            print("   âœ… NVIDIA Container Toolkitå·²å®‰è£…")
        else:
            print("   âŒ NVIDIA Container Toolkitæœªå®‰è£…")
    except:
        print("   âŒ æ£€æŸ¥å¤±è´¥")
    
    # 5. æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ
    print("\n5. ğŸ Pythonç¯å¢ƒ:")
    venv_path = "file_processing_website/backend/.venv"
    if os.path.exists(venv_path):
        print(f"   âœ… è™šæ‹Ÿç¯å¢ƒå­˜åœ¨: {venv_path}")
        
        # æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒä¸­çš„PyTorch
        try:
            activate_script = f"{venv_path}/bin/activate"
            if os.path.exists(activate_script):
                cmd = f"source {activate_script} && python -c \"import torch; print('PyTorch:', torch.__version__, 'CUDA:', torch.cuda.is_available())\""
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
                if result.returncode == 0:
                    print(f"   PyTorchçŠ¶æ€: {result.stdout.strip()}")
                else:
                    print(f"   PyTorchæ£€æŸ¥å¤±è´¥: {result.stderr.strip()}")
        except Exception as e:
            print(f"   PyTorchæ£€æŸ¥å¼‚å¸¸: {e}")
    else:
        print(f"   âŒ è™šæ‹Ÿç¯å¢ƒä¸å­˜åœ¨: {venv_path}")
    
    # 6. æ£€æŸ¥MonkeyOCRé…ç½®
    print("\n6. ğŸ”§ MonkeyOCRé…ç½®:")
    config_file = "model_configs.yaml"
    if os.path.exists(config_file):
        print(f"   âœ… é…ç½®æ–‡ä»¶å­˜åœ¨: {config_file}")
        try:
            with open(config_file, 'r', encoding='utf-8') as f:
                content = f.read()
                if 'device: cuda' in content:
                    print("   âš ï¸  å½“å‰é…ç½®: device=cuda (éœ€è¦GPU)")
                elif 'device: cpu' in content:
                    print("   âœ… å½“å‰é…ç½®: device=cpu (CPUæ¨¡å¼)")
                else:
                    print("   â“ è®¾å¤‡é…ç½®ä¸æ˜ç¡®")
        except Exception as e:
            print(f"   âŒ é…ç½®æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
    else:
        print(f"   âŒ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
    
    # 7. æ¨èæ–¹æ¡ˆ
    print("\n7. ğŸ’¡ æ¨èæ–¹æ¡ˆ:")
    print("   åŸºäºå½“å‰ç¯å¢ƒåˆ†æ:")
    print("   - ç³»ç»Ÿ: VMwareè™šæ‹Ÿæœº")
    print("   - æ˜¾å¡: è™šæ‹Ÿæ˜¾å¡ (VMware SVGA)")
    print("   - NVIDIAé©±åŠ¨: æœªå®‰è£…")
    print("   - Docker: å·²å®‰è£…")
    print("   - GPUæ”¯æŒ: å·²é…ç½®ä½†æ— ç‰©ç†GPU")
    print()
    print("   ğŸ¯ å»ºè®®ä½¿ç”¨æ–¹æ¡ˆ:")
    print("   1. âœ… Docker CPUç‰ˆæœ¬ (æ¨è)")
    print("      - ç¨³å®šå¯é ")
    print("      - åŠŸèƒ½å®Œæ•´")
    print("      - é€‚åˆå¼€å‘æµ‹è¯•")
    print("   2. âš ï¸  ä¿®æ”¹é…ç½®ä½¿ç”¨CPUæ¨¡å¼")
    print("      - ä¿®æ”¹model_configs.yamlä¸­device: cpu")
    print("      - ç›´æ¥åœ¨å®¿ä¸»æœºè¿è¡Œ")
    print("   3. ğŸŒ ä½¿ç”¨äº‘GPUå®ä¾‹")
    print("      - æ€§èƒ½æœ€ä½³")
    print("      - é€‚åˆç”Ÿäº§ç¯å¢ƒ")
    
    print("\n" + "=" * 60)
    print("ğŸ æµ‹è¯•å®Œæˆ")
    print("ğŸ’¡ å»ºè®®: ä½¿ç”¨Docker CPUç‰ˆæœ¬å¼€å§‹ä½“éªŒMonkeyOCRåŠŸèƒ½")

if __name__ == "__main__":
    test_current_setup() 