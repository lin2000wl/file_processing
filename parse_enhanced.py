#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆPDFå¤„ç†è„šæœ¬
æ•´åˆäº†åŸæœ‰çš„PDFå¤„ç†åŠŸèƒ½å’Œæ–°çš„å¢å¼ºåŠŸèƒ½ï¼š
1. åŸæœ‰çš„PDF/å›¾åƒè§£æåŠŸèƒ½
2. ç”ŸæˆPDFæ¯é¡µå®Œæ•´æˆªå›¾
3. ç”Ÿæˆå¸¦é¡µé¢ä¿¡æ¯çš„TXTæ–‡ä»¶

åŸºäºåŸæœ‰parse.pyçš„åŠŸèƒ½ï¼Œæ·»åŠ äº†åå¤„ç†å¢å¼ºåŠŸèƒ½
"""

import os
import time
import argparse
import sys
import json
import re
from pathlib import Path
from PIL import Image
import fitz  # PyMuPDF
import torch.distributed as dist
from pdf2image import convert_from_path

# å¯¼å…¥åŸæœ‰çš„æ¨¡å—
from magic_pdf.data.data_reader_writer import FileBasedDataWriter, FileBasedDataReader
from magic_pdf.data.dataset import PymuDocDataset, ImageDataset, MultiFileDataset
from magic_pdf.model.doc_analyze_by_custom_model_llm import doc_analyze_llm
from magic_pdf.model.custom_model import MonkeyOCR

# ä»»åŠ¡æŒ‡ä»¤å®šä¹‰
TASK_INSTRUCTIONS = {
    'text': 'Please output the text content from the image.',
    'formula': 'Please write out the expression of the formula in the image using LaTeX format.',
    'table': 'This is the image of a table. Please output the table in html format.'
}


class EnhancedPDFProcessor:
    """å¢å¼ºçš„PDFå¤„ç†å™¨"""
    
    def __init__(self, config_path="model_configs.yaml"):
        """
        åˆå§‹åŒ–å¤„ç†å™¨
        
        Args:
            config_path: æ¨¡å‹é…ç½®æ–‡ä»¶è·¯å¾„
        """
        self.config_path = config_path
        self.MonkeyOCR_model = None
    
    def _load_model(self):
        """åŠ è½½æ¨¡å‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
        if self.MonkeyOCR_model is None:
            print("Loading model...")
            self.MonkeyOCR_model = MonkeyOCR(self.config_path)
        return self.MonkeyOCR_model
    
    def generate_page_images(self, pdf_path: str, result_dir: str, pdf_name: str) -> bool:
        """
        ç”ŸæˆPDFæ¯é¡µå®Œæ•´æˆªå›¾
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            result_dir: ç»“æœç›®å½•
            pdf_name: PDFæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸç”Ÿæˆ
        """
        if not os.path.exists(pdf_path):
            print(f"âš ï¸  PDFæ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡é¡µé¢æˆªå›¾ç”Ÿæˆ: {pdf_path}")
            return False
        
        # åˆ›å»ºé¡µé¢å›¾åƒç›®å½•
        page_images_dir = os.path.join(result_dir, "page_images")
        os.makedirs(page_images_dir, exist_ok=True)
        
        try:
            # æ‰“å¼€PDFæ–‡ä»¶
            pdf_doc = fitz.open(pdf_path)
            
            print(f"ğŸ–¼ï¸  ç”Ÿæˆé¡µé¢æˆªå›¾ï¼Œå…± {len(pdf_doc)} é¡µ...")
            
            for page_num in range(len(pdf_doc)):
                page = pdf_doc[page_num]
                
                # ç”Ÿæˆé¡µé¢å›¾åƒ
                mat = fitz.Matrix(2.0, 2.0)  # 2å€ç¼©æ”¾ï¼Œæé«˜æ¸…æ™°åº¦
                pix = page.get_pixmap(matrix=mat, alpha=False)
                
                # ä¿å­˜å›¾åƒ
                image_filename = f"{pdf_name}_page_{page_num + 1}.png"
                image_path = os.path.join(page_images_dir, image_filename)
                pix.save(image_path)
                
                print(f"   âœ… ç”Ÿæˆé¡µé¢ {page_num + 1}: {image_filename}")
            
            pdf_doc.close()
            print(f"ğŸ‰ é¡µé¢æˆªå›¾ç”Ÿæˆå®Œæˆï¼")
            return True
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆé¡µé¢æˆªå›¾æ—¶å‡ºé”™: {e}")
            return False
    
    def generate_txt_file(self, result_dir: str, pdf_name: str) -> bool:
        """
        ç”Ÿæˆå¸¦é¡µé¢ä¿¡æ¯çš„TXTæ–‡ä»¶
        
        Args:
            result_dir: ç»“æœç›®å½•
            pdf_name: PDFæ–‡ä»¶åï¼ˆä¸å«æ‰©å±•åï¼‰
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸç”Ÿæˆ
        """
        # æŸ¥æ‰¾Markdownæ–‡ä»¶
        md_file = os.path.join(result_dir, f"{pdf_name}.md")
        if not os.path.exists(md_file):
            print(f"âš ï¸  æœªæ‰¾åˆ°Markdownæ–‡ä»¶ï¼Œè·³è¿‡TXTç”Ÿæˆ: {md_file}")
            return False
        
        # æŸ¥æ‰¾ä¸­é—´JSONæ–‡ä»¶
        middle_json = os.path.join(result_dir, f"{pdf_name}_middle.json")
        
        try:
            # è¯»å–Markdownå†…å®¹
            with open(md_file, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # è¯»å–ä¸­é—´ç»“æœJSONï¼ˆç”¨äºè·å–é¡µé¢ä¿¡æ¯ï¼‰
            page_info = self._get_page_info_from_json(middle_json)
            
            # å¤„ç†Markdownå†…å®¹
            txt_content = self._process_markdown_to_txt(md_content, page_info, pdf_name)
            
            # ä¿å­˜TXTæ–‡ä»¶åˆ°txtç›®å½•
            txt_filename = f"{pdf_name}.txt"
            # ç¡®ä¿txtç›®å½•å­˜åœ¨
            txt_dir = "txt"
            os.makedirs(txt_dir, exist_ok=True)
            txt_path = os.path.join(txt_dir, txt_filename)
            
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(txt_content)
            
            print(f"ğŸ“„ TXTæ–‡ä»¶ç”Ÿæˆå®Œæˆ: {txt_filename}")
            return True
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆTXTæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False
    
    def _get_page_info_from_json(self, middle_json_path: str) -> dict:
        """ä»ä¸­é—´ç»“æœJSONä¸­è·å–é¡µé¢ä¿¡æ¯"""
        if not os.path.exists(middle_json_path):
            return {}
        
        try:
            with open(middle_json_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æå–é¡µé¢ä¿¡æ¯
            pdf_info = data.get('pdf_info', [])
            page_info = {}
            
            for page_data in pdf_info:
                page_idx = page_data.get('page_idx', 0)
                
                # å°è¯•è·å–ä¸åŒå­—æ®µåçš„å—æ•°æ®
                blocks = page_data.get('para_blocks', [])
                if not blocks:
                    blocks = page_data.get('preproc_blocks', [])
                
                page_info[page_idx] = {
                    'page_num': page_idx + 1,
                    'blocks': blocks
                }
            
            return page_info
            
        except Exception as e:
            print(f"âš ï¸  è¯»å–é¡µé¢ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return {}

    def _process_page_blocks(self, blocks: list, pdf_name: str) -> str:
        """
        å¤„ç†é¡µé¢å—å†…å®¹ï¼Œç”Ÿæˆæ–‡æœ¬å†…å®¹
        
        Args:
            blocks: é¡µé¢å—æ•°æ®åˆ—è¡¨
            pdf_name: PDFæ–‡ä»¶å
            
        Returns:
            str: å¤„ç†åçš„é¡µé¢å†…å®¹
        """
        content_lines = []
        
        for block in blocks:
            block_content = self._process_single_block(block, pdf_name)
            if block_content.strip():
                content_lines.append(block_content)
        
        return "\n\n".join(content_lines)
    
    def _process_single_block(self, block: dict, pdf_name: str) -> str:
        """
        å¤„ç†å•ä¸ªå—
        
        Args:
            block: å—æ•°æ®
            pdf_name: PDFæ–‡ä»¶å
            
        Returns:
            str: å¤„ç†åçš„å—å†…å®¹
        """
        block_type = block.get('type', '')
        
        if block_type == 'text':
            return self._process_text_block(block)
        elif block_type == 'title':
            return self._process_title_block(block)
        elif block_type == 'inter_line_equation':
            return self._process_equation_block(block)
        elif block_type == 'table':
            return self._process_table_block(block)
        elif block_type == 'image':
            return self._process_image_block(block, pdf_name)
        elif block_type == 'list':
            return self._process_list_block(block)
        else:
            # é€šç”¨å¤„ç†
            return self._extract_text_from_block(block)
    
    def _process_text_block(self, block: dict) -> str:
        """å¤„ç†æ–‡æœ¬å—"""
        lines = block.get('lines', [])
        text_content = []
        
        for line in lines:
            spans = line.get('spans', [])
            line_text = ""
            
            for span in spans:
                span_text = span.get('content', '').strip()
                if span_text:
                    line_text += span_text + " "
            
            if line_text.strip():
                text_content.append(line_text.strip())
        
        return "\n".join(text_content)
    
    def _process_title_block(self, block: dict) -> str:
        """å¤„ç†æ ‡é¢˜å—"""
        title_text = self._extract_text_from_block(block)
        if title_text.strip():
            # ç§»é™¤Markdownæ ¼å¼çš„#å·
            title_text = re.sub(r'^#+\s*', '', title_text.strip())
            return f"{title_text}\n{'-' * len(title_text)}"  # æ·»åŠ ä¸‹åˆ’çº¿
        return ""
    
    def _process_equation_block(self, block: dict) -> str:
        """å¤„ç†å…¬å¼å—"""
        latex_text = block.get('latex', '')
        if latex_text:
            return f"[å…¬å¼] {latex_text}"
        return self._extract_text_from_block(block)
    
    def _process_table_block(self, block: dict) -> str:
        """å¤„ç†è¡¨æ ¼å—"""
        html_content = block.get('html', '')
        if html_content:
            # ç®€å•çš„HTMLè¡¨æ ¼è½¬æ–‡æœ¬
            table_text = self._html_table_to_text(html_content)
            return f"[è¡¨æ ¼]\n{table_text}"
        return self._extract_text_from_block(block)
    
    def _process_image_block(self, block: dict, pdf_name: str) -> str:
        """å¤„ç†å›¾åƒå—"""
        image_info = []
        image_path = None
        image_caption = None
        
        # ä»blocksä¸­æå–å›¾ç‰‡ä¿¡æ¯
        blocks = block.get('blocks', [])
        for sub_block in blocks:
            block_type = sub_block.get('type', '')
            
            if block_type == 'image_body':
                # æå–å›¾ç‰‡è·¯å¾„
                lines = sub_block.get('lines', [])
                for line in lines:
                    spans = line.get('spans', [])
                    for span in spans:
                        if span.get('type') == 'image':
                            image_path = span.get('image_path', '')
                            break
                    if image_path:
                        break
                        
            elif block_type == 'image_caption':
                # æå–å›¾ç‰‡æ ‡é¢˜
                lines = sub_block.get('lines', [])
                for line in lines:
                    spans = line.get('spans', [])
                    for span in spans:
                        caption_text = span.get('content', '').strip()
                        if caption_text:
                            image_caption = caption_text
                            break
                    if image_caption:
                        break
        
        # æ„å»ºå›¾ç‰‡ä¿¡æ¯ï¼Œä½¿ç”¨æ–°çš„URLæ ¼å¼
        if image_path:
            # æ–°çš„å›¾ç‰‡URLæ ¼å¼ï¼šhttp://9bn8of823990.vicp.fun:42712/images/æ–‡ä»¶å/images/ç›¸å¯¹å›¾ç‰‡è·¯å¾„
            image_url = f"http://9bn8of823990.vicp.fun:42712/images/{pdf_name}/images/{image_path}"
            image_info.append(f"[å›¾åƒ] {image_url}")
        else:
            image_info.append("[å›¾åƒ]")
            
        if image_caption:
            image_info.append(image_caption)
        
        return "\n".join(image_info) if image_info else "[å›¾åƒ]"
    
    def _process_list_block(self, block: dict) -> str:
        """å¤„ç†åˆ—è¡¨å—"""
        lines = block.get('lines', [])
        list_items = []
        
        for line in lines:
            line_text = self._extract_text_from_line(line)
            if line_text.strip():
                list_items.append(f"â€¢ {line_text.strip()}")
        
        return "\n".join(list_items)
    
    def _extract_text_from_block(self, block: dict) -> str:
        """ä»å—ä¸­æå–æ–‡æœ¬"""
        lines = block.get('lines', [])
        text_content = []
        
        for line in lines:
            line_text = self._extract_text_from_line(line)
            if line_text.strip():
                text_content.append(line_text.strip())
        
        return "\n".join(text_content)
    
    def _extract_text_from_line(self, line: dict) -> str:
        """ä»è¡Œä¸­æå–æ–‡æœ¬"""
        spans = line.get('spans', [])
        line_text = ""
        
        for span in spans:
            span_text = span.get('content', '').strip()
            if span_text:
                line_text += span_text + " "
        
        return line_text.strip()
    
    def _html_table_to_text(self, html_content: str) -> str:
        """å°†HTMLè¡¨æ ¼è½¬æ¢ä¸ºæ–‡æœ¬æ ¼å¼"""
        import re
        # ç®€å•çš„HTMLè¡¨æ ¼è§£æ
        try:
            # ç§»é™¤HTMLæ ‡ç­¾ï¼Œä¿ç•™å†…å®¹
            text_content = re.sub(r'<[^>]+>', ' ', html_content)
            # æ¸…ç†å¤šä½™ç©ºæ ¼
            text_content = re.sub(r'\s+', ' ', text_content)
            return text_content.strip()
        except Exception:
            return "[è¡¨æ ¼å†…å®¹]"
    
    def _process_markdown_to_txt(self, md_content: str, page_info: dict, pdf_name: str) -> str:
        """
        å¤„ç†Markdownå†…å®¹è½¬æ¢ä¸ºTXTæ ¼å¼
        
        Args:
            md_content: Markdownå†…å®¹
            page_info: é¡µé¢ä¿¡æ¯å­—å…¸
            pdf_name: PDFæ–‡ä»¶å
            
        Returns:
            str: å¤„ç†åçš„TXTå†…å®¹
        """
        # å»é™¤Markdownæ ¼å¼
        txt_content = self._remove_markdown_formatting(md_content)
        
        # å¦‚æœæœ‰é¡µé¢ä¿¡æ¯ï¼ŒæŒ‰é¡µé¢é‡æ–°ç»„ç»‡å†…å®¹
        if page_info:
            txt_content = self._reorganize_by_pages(txt_content, page_info, pdf_name)
        else:
            # å¦‚æœæ²¡æœ‰é¡µé¢ä¿¡æ¯ï¼Œä½¿ç”¨ç®€å•çš„é¡µé¢åˆ†å‰²
            txt_content = self._add_page_headers_simple(txt_content, pdf_name)
        
        return txt_content
    
    def _remove_markdown_formatting(self, md_content: str) -> str:
        """å»é™¤Markdownæ ¼å¼"""
        # å»é™¤æ ‡é¢˜çš„#å·
        content = re.sub(r'^#+\s*', '', md_content, flags=re.MULTILINE)
        
        # å»é™¤å…¶ä»–Markdownæ ¼å¼
        content = re.sub(r'\*\*(.*?)\*\*', r'\1', content)  # ç²—ä½“
        content = re.sub(r'\*(.*?)\*', r'\1', content)      # æ–œä½“
        content = re.sub(r'`(.*?)`', r'\1', content)        # ä»£ç 
        content = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', content)  # é“¾æ¥
        
        return content
    
    def _reorganize_by_pages(self, content: str, page_info: dict, pdf_name: str) -> str:
        """åŸºäºé¡µé¢ä¿¡æ¯é‡æ–°ç»„ç»‡å†…å®¹"""
        organized_content = []
        
        for page_idx in sorted(page_info.keys()):
            page_data = page_info[page_idx]
            page_num = page_data['page_num']
            blocks = page_data.get('blocks', [])
            
            # æ·»åŠ é¡µé¢å¤´éƒ¨ï¼ˆæ–°æ ¼å¼ï¼šæ·»åŠ #å·å’Œæ–°çš„å›¾ç‰‡URLï¼‰
            page_image_url = f"http://9bn8of823990.vicp.fun:42712/images/{pdf_name}/page_images/{pdf_name}_page_{page_num}.png"
            page_header = f"#ï¼ˆ{pdf_name}ï¼‰ç¬¬{page_num}é¡µåŸå›¾å†…å®¹ï¼š{page_image_url}"
            
            organized_content.append(page_header)
            organized_content.append("&&é¡µé¢å†…å®¹...")  # æ·»åŠ &&æ ‡è®°
            organized_content.append("")  # ç©ºè¡Œ
            
            # å¤„ç†å®é™…çš„é¡µé¢å†…å®¹
            if blocks:
                page_content = self._process_page_blocks(blocks, pdf_name)
                if page_content.strip():
                    organized_content.append(page_content)
                else:
                    organized_content.append(f"[ç¬¬{page_num}é¡µæ— æ–‡æœ¬å†…å®¹]")
            else:
                organized_content.append(f"[ç¬¬{page_num}é¡µæ— å—æ•°æ®]")
            
            organized_content.append("")  # é¡µé¢é—´ç©ºè¡Œ
            organized_content.append("=" * 50)  # é¡µé¢åˆ†éš”çº¿
            organized_content.append("")
        
        return "\n".join(organized_content)
    
    def _add_page_headers_simple(self, content: str, pdf_name: str) -> str:
        """ç®€å•çš„é¡µé¢å¤´éƒ¨æ·»åŠ ï¼ˆå½“æ²¡æœ‰è¯¦ç»†é¡µé¢ä¿¡æ¯æ—¶ï¼‰"""
        lines = content.split('\n')
        processed_lines = []
        
        page_num = 1
        line_count = 0
        
        for line in lines:
            # æ¯50è¡Œä½œä¸ºä¸€é¡µï¼ˆå¯è°ƒæ•´ï¼‰
            if line_count % 50 == 0 and line_count > 0:
                page_num += 1
            
            # åœ¨æ¯é¡µå¼€å§‹æ·»åŠ é¡µé¢ä¿¡æ¯ï¼ˆæ–°æ ¼å¼ï¼šæ·»åŠ #å·å’Œ&&ï¼‰
            if line_count % 50 == 0:
                page_image_url = f"page_images/{pdf_name}_page_{page_num}.png"
                page_header = f"#ï¼ˆ{pdf_name}ï¼‰ç¬¬{page_num}é¡µåŸå›¾å†…å®¹ï¼š{page_image_url}"
                processed_lines.append(page_header)
                processed_lines.append("&&é¡µé¢å†…å®¹...")  # æ·»åŠ &&æ ‡è®°
                processed_lines.append("")  # ç©ºè¡Œ
            
            processed_lines.append(line)
            line_count += 1
        
        return "\n".join(processed_lines)
    
    def parse_file_enhanced(self, input_file: str, output_dir: str, split_pages: bool = False, 
                           enable_enhancements: bool = True) -> str:
        """
        å¢å¼ºç‰ˆæ–‡ä»¶è§£æï¼ˆæ•´åˆäº†åŸæœ‰åŠŸèƒ½å’Œæ–°åŠŸèƒ½ï¼‰
        
        Args:
            input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            split_pages: æ˜¯å¦åˆ†é¡µå¤„ç†
            enable_enhancements: æ˜¯å¦å¯ç”¨å¢å¼ºåŠŸèƒ½
            
        Returns:
            str: ç»“æœç›®å½•è·¯å¾„
        """
        print(f"ğŸš€ å¼€å§‹å¢å¼ºç‰ˆè§£æ: {input_file}")
        
        # æ£€æŸ¥è¾“å…¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        if not os.path.exists(input_file):
            raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        
        # è·å–æ–‡ä»¶å
        name_without_suff = '.'.join(os.path.basename(input_file).split(".")[:-1])
        
        # å‡†å¤‡è¾“å‡ºç›®å½•
        local_image_dir = os.path.join(output_dir, name_without_suff, "images")
        local_md_dir = os.path.join(output_dir, name_without_suff)
        image_dir = os.path.basename(local_image_dir)
        os.makedirs(local_image_dir, exist_ok=True)
        os.makedirs(local_md_dir, exist_ok=True)
        
        print(f"ğŸ“ è¾“å‡ºç›®å½•: {local_md_dir}")
        image_writer = FileBasedDataWriter(local_image_dir)
        md_writer = FileBasedDataWriter(local_md_dir)
        
        # è¯»å–æ–‡ä»¶å†…å®¹
        reader = FileBasedDataReader()
        file_bytes = reader.read(input_file)
        
        # åˆ›å»ºæ•°æ®é›†å®ä¾‹
        file_extension = input_file.split(".")[-1].lower()
        if file_extension == "pdf":
            ds = PymuDocDataset(file_bytes)
        else:
            ds = ImageDataset(file_bytes)
        
        # å¼€å§‹æ¨ç†
        print("ğŸ” æ‰§è¡Œæ–‡æ¡£è§£æ...")
        start_time = time.time()
        
        model = self._load_model()
        infer_result = ds.apply(doc_analyze_llm, MonkeyOCR_model=model, split_pages=split_pages)
        
        parsing_time = time.time() - start_time
        print(f"â±ï¸  è§£ææ—¶é—´: {parsing_time:.2f}s")

        # æ£€æŸ¥æ¨ç†ç»“æœæ˜¯å¦ä¸ºåˆ—è¡¨ç±»å‹
        if isinstance(infer_result, list):
            print(f"ğŸ“„ åˆ†åˆ«å¤„ç† {len(infer_result)} é¡µ...")
            
            # åˆ†åˆ«å¤„ç†æ¯é¡µç»“æœ
            for page_idx, page_infer_result in enumerate(infer_result):
                page_dir_name = f"page_{page_idx}"
                page_local_image_dir = os.path.join(output_dir, name_without_suff, page_dir_name, "images")
                page_local_md_dir = os.path.join(output_dir, name_without_suff, page_dir_name)
                page_image_dir = os.path.basename(page_local_image_dir)
                
                # åˆ›å»ºé¡µé¢ç‰¹å®šç›®å½•
                os.makedirs(page_local_image_dir, exist_ok=True)
                os.makedirs(page_local_md_dir, exist_ok=True)
                
                # åˆ›å»ºé¡µé¢ç‰¹å®šå†™å…¥å™¨
                page_image_writer = FileBasedDataWriter(page_local_image_dir)
                page_md_writer = FileBasedDataWriter(page_local_md_dir)
                
                print(f"ğŸ“„ å¤„ç†ç¬¬ {page_idx} é¡µ - è¾“å‡ºç›®å½•: {page_local_md_dir}")
                
                # è¯¥é¡µçš„ç®¡é“å¤„ç†
                page_pipe_result = page_infer_result.pipe_ocr_mode(page_image_writer, MonkeyOCR_model=model)
                
                # ä¿å­˜é¡µé¢ç‰¹å®šç»“æœ
                page_infer_result.draw_model(os.path.join(page_local_md_dir, f"{name_without_suff}_page_{page_idx}_model.pdf"))
                page_pipe_result.draw_layout(os.path.join(page_local_md_dir, f"{name_without_suff}_page_{page_idx}_layout.pdf"))
                page_pipe_result.draw_span(os.path.join(page_local_md_dir, f"{name_without_suff}_page_{page_idx}_spans.pdf"))
                page_pipe_result.dump_md(page_md_writer, f"{name_without_suff}_page_{page_idx}.md", page_image_dir)
                page_pipe_result.dump_content_list(page_md_writer, f"{name_without_suff}_page_{page_idx}_content_list.json", page_image_dir)
                page_pipe_result.dump_middle_json(page_md_writer, f'{name_without_suff}_page_{page_idx}_middle.json')
            
            print(f"âœ… æ‰€æœ‰ {len(infer_result)} é¡µå¤„ç†å®Œæˆå¹¶ä¿å­˜åœ¨ç‹¬ç«‹å­ç›®å½•ä¸­")
        else:
            print("ğŸ“„ ä½œä¸ºå•ä¸ªç»“æœå¤„ç†...")
            
            # å•ä¸ªç»“æœçš„ç®¡é“å¤„ç†
            pipe_result = infer_result.pipe_ocr_mode(image_writer, MonkeyOCR_model=model)
            
            # ä¿å­˜å•ä¸ªç»“æœï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            infer_result.draw_model(os.path.join(local_md_dir, f"{name_without_suff}_model.pdf"))
            pipe_result.draw_layout(os.path.join(local_md_dir, f"{name_without_suff}_layout.pdf"))
            pipe_result.draw_span(os.path.join(local_md_dir, f"{name_without_suff}_spans.pdf"))
            pipe_result.dump_md(md_writer, f"{name_without_suff}.md", image_dir)
            pipe_result.dump_content_list(md_writer, f"{name_without_suff}_content_list.json", image_dir)
            pipe_result.dump_middle_json(md_writer, f'{name_without_suff}_middle.json')
        
        print("ğŸ’¾ åŸæœ‰å¤„ç†ç»“æœå·²ä¿å­˜")
        
        # æ‰§è¡Œå¢å¼ºåŠŸèƒ½
        if enable_enhancements:
            print("ğŸ¯ å¼€å§‹æ‰§è¡Œå¢å¼ºåŠŸèƒ½...")
            
            enhancement_success = 0
            
            # åŠŸèƒ½1: ç”Ÿæˆé¡µé¢æˆªå›¾ï¼ˆä»…å¯¹PDFæ–‡ä»¶ï¼‰
            if file_extension == "pdf":
                if self.generate_page_images(input_file, local_md_dir, name_without_suff):
                    enhancement_success += 1
            else:
                print("âš ï¸  éPDFæ–‡ä»¶ï¼Œè·³è¿‡é¡µé¢æˆªå›¾ç”Ÿæˆ")
            
            # åŠŸèƒ½2: ç”ŸæˆTXTæ–‡ä»¶
            if self.generate_txt_file(local_md_dir, name_without_suff):
                enhancement_success += 1
            
            print(f"âœ¨ å¢å¼ºåŠŸèƒ½å®Œæˆï¼æˆåŠŸ: {enhancement_success}/2")
        
        print(f"ğŸ‰ å®Œæ•´å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åˆ°: {local_md_dir}")
        return local_md_dir


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="å¢å¼ºç‰ˆPDFæ–‡æ¡£è§£æå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•ï¼ˆåŒ…å«å¢å¼ºåŠŸèƒ½ï¼‰
  python parse_enhanced.py input.pdf                    # è§£æPDFå¹¶ç”Ÿæˆå¢å¼ºåŠŸèƒ½
  python parse_enhanced.py input.pdf -o ./output        # æŒ‡å®šè¾“å‡ºç›®å½•
  python parse_enhanced.py input.pdf -s                 # åˆ†é¡µå¤„ç†
  python parse_enhanced.py image.jpg                    # è§£æå›¾åƒæ–‡ä»¶
  
  # ç¦ç”¨å¢å¼ºåŠŸèƒ½ï¼ˆä»…ä½¿ç”¨åŸæœ‰åŠŸèƒ½ï¼‰
  python parse_enhanced.py input.pdf --no-enhancements  # ä»…åŸæœ‰åŠŸèƒ½
  
  # è‡ªå®šä¹‰é…ç½®
  python parse_enhanced.py input.pdf -c model_configs.yaml  # è‡ªå®šä¹‰æ¨¡å‹é…ç½®
  
  # å®Œæ•´ç¤ºä¾‹
  python parse_enhanced.py document.pdf -o ./results -s -c config.yaml
        """
    )
    
    parser.add_argument(
        "input_file",
        help="è¾“å…¥PDFæˆ–å›¾åƒæ–‡ä»¶è·¯å¾„"
    )
    
    parser.add_argument(
        "-o", "--output",
        default="./output",
        help="è¾“å‡ºç›®å½• (é»˜è®¤: ./output)"
    )
    
    parser.add_argument(
        "-c", "--config",
        default="model_configs.yaml",
        help="é…ç½®æ–‡ä»¶è·¯å¾„ (é»˜è®¤: model_configs.yaml)"
    )
    
    parser.add_argument(
        "-s", "--split_pages",
        action='store_true',
        help="å°†PDFé¡µé¢è¾“å‡ºåˆ†å‰²ä¸ºç‹¬ç«‹çš„ç»“æœ (é»˜è®¤: False)"
    )
    
    parser.add_argument(
        "--no-enhancements",
        action='store_true',
        help="ç¦ç”¨å¢å¼ºåŠŸèƒ½ï¼Œä»…ä½¿ç”¨åŸæœ‰åŠŸèƒ½"
    )
    
    args = parser.parse_args()
    
    try:
        # æ£€æŸ¥è¾“å…¥è·¯å¾„æ˜¯å¦ä¸ºæ–‡ä»¶
        if not os.path.isfile(args.input_file):
            print(f"âŒ è¾“å…¥å¿…é¡»æ˜¯æ–‡ä»¶: {args.input_file}")
            sys.exit(1)
        
        # åˆ›å»ºå¢å¼ºå¤„ç†å™¨
        processor = EnhancedPDFProcessor(args.config)
        
        # æ‰§è¡Œå¢å¼ºå¤„ç†
        result_dir = processor.parse_file_enhanced(
            args.input_file,
            args.output,
            args.split_pages,
            not args.no_enhancements  # å–åï¼Œå› ä¸ºå‚æ•°æ˜¯no-enhancements
        )
        
        if args.no_enhancements:
            print(f"\nâœ… åŸæœ‰åŠŸèƒ½å¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {result_dir}")
        else:
            print(f"\nğŸ‰ å¢å¼ºç‰ˆå¤„ç†å®Œæˆï¼ç»“æœä¿å­˜åœ¨: {result_dir}")
            print("\nğŸ“Š ç”Ÿæˆçš„æ–‡ä»¶:")
            print("   - *.md          - Markdownæ–‡ä»¶")
            print("   - *.txt         - å¢å¼ºTXTæ–‡ä»¶")
            print("   - *_layout.pdf  - ç‰ˆé¢æ ‡æ³¨PDF")
            print("   - *_middle.json - ä¸­é—´ç»“æœJSON")
            print("   - images/       - æå–çš„å›¾åƒ")
            print("   - page_images/  - é¡µé¢å®Œæ•´æˆªå›¾")
        
    except Exception as e:
        print(f"âŒ å¤„ç†å¤±è´¥: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main() 