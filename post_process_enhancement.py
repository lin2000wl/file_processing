#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
PDFå¤„ç†ç»“æœå¢å¼ºè„šæœ¬
åŸºäºç°æœ‰çš„PDFå¤„ç†è¾“å‡ºç»“æœï¼Œç”Ÿæˆé¢å¤–çš„åŠŸèƒ½ï¼š
1. ç”ŸæˆPDFæ¯é¡µå®Œæ•´æˆªå›¾
2. ç”Ÿæˆå¸¦é¡µé¢ä¿¡æ¯çš„TXTæ–‡ä»¶
"""

import os
import json
import argparse
import re
from pathlib import Path
from PIL import Image
import fitz  # PyMuPDF
from typing import Dict, List, Optional


class PDFEnhancementProcessor:
    """PDFå¤„ç†ç»“æœå¢å¼ºå™¨"""
    
    def __init__(self, result_dir: str):
        """
        åˆå§‹åŒ–å¢å¼ºå¤„ç†å™¨
        
        Args:
            result_dir: ç°æœ‰å¤„ç†ç»“æœç›®å½•
        """
        self.result_dir = Path(result_dir)
        self.pdf_name = self.result_dir.name
        
        # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨
        self.md_file = self._find_md_file()
        self.middle_json = self._find_middle_json()
        self.original_pdf = self._find_original_pdf()
        
    def _find_md_file(self) -> Optional[Path]:
        """æŸ¥æ‰¾Markdownæ–‡ä»¶"""
        md_files = list(self.result_dir.glob("*.md"))
        return md_files[0] if md_files else None
    
    def _find_middle_json(self) -> Optional[Path]:
        """æŸ¥æ‰¾ä¸­é—´ç»“æœJSONæ–‡ä»¶"""
        json_files = list(self.result_dir.glob("*_middle.json"))
        return json_files[0] if json_files else None
    
    def _find_original_pdf(self) -> Optional[Path]:
        """æŸ¥æ‰¾åŸå§‹PDFæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨ï¼‰"""
        # å°è¯•ä»ä¸Šçº§ç›®å½•æˆ–å…¶ä»–ä½ç½®æŸ¥æ‰¾åŸå§‹PDF
        pdf_files = list(self.result_dir.parent.glob(f"{self.pdf_name}.pdf"))
        if not pdf_files:
            pdf_files = list(self.result_dir.glob("*.pdf"))
        return pdf_files[0] if pdf_files else None
    
    def generate_page_images(self, pdf_path: str = None) -> bool:
        """
        ç”ŸæˆPDFæ¯é¡µå®Œæ•´æˆªå›¾
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœä¸æä¾›åˆ™å°è¯•è‡ªåŠ¨æŸ¥æ‰¾
            
        Returns:
            bool: æ˜¯å¦æˆåŠŸç”Ÿæˆ
        """
        if pdf_path is None:
            pdf_path = self.original_pdf
        
        if not pdf_path or not os.path.exists(pdf_path):
            print(f"âŒ æœªæ‰¾åˆ°PDFæ–‡ä»¶: {pdf_path}")
            return False
        
        # åˆ›å»ºé¡µé¢å›¾åƒç›®å½•
        page_images_dir = self.result_dir / "page_images"
        page_images_dir.mkdir(exist_ok=True)
        
        try:
            # æ‰“å¼€PDFæ–‡ä»¶
            pdf_doc = fitz.open(str(pdf_path))
            
            print(f"ğŸ–¼ï¸  å¼€å§‹ç”Ÿæˆé¡µé¢æˆªå›¾ï¼Œå…± {len(pdf_doc)} é¡µ...")
            
            for page_num in range(len(pdf_doc)):
                page = pdf_doc[page_num]
                
                # ç”Ÿæˆé¡µé¢å›¾åƒ
                mat = fitz.Matrix(2.0, 2.0)  # 2å€ç¼©æ”¾ï¼Œæé«˜æ¸…æ™°åº¦
                pix = page.get_pixmap(matrix=mat, alpha=False)
                
                # ä¿å­˜å›¾åƒ
                image_filename = f"{self.pdf_name}_page_{page_num + 1}.png"
                image_path = page_images_dir / image_filename
                pix.save(str(image_path))
                
                print(f"   âœ… ç”Ÿæˆé¡µé¢ {page_num + 1}: {image_filename}")
            
            pdf_doc.close()
            print(f"ğŸ‰ é¡µé¢æˆªå›¾ç”Ÿæˆå®Œæˆï¼ä¿å­˜ä½ç½®: {page_images_dir}")
            return True
            
        except Exception as e:
            print(f"âŒ ç”Ÿæˆé¡µé¢æˆªå›¾æ—¶å‡ºé”™: {e}")
            return False
    
    def generate_txt_file(self) -> bool:
        """
        ç”Ÿæˆå¸¦é¡µé¢ä¿¡æ¯çš„TXTæ–‡ä»¶
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸç”Ÿæˆ
        """
        if not self.md_file or not self.md_file.exists():
            print(f"âŒ æœªæ‰¾åˆ°Markdownæ–‡ä»¶: {self.md_file}")
            return False
        
        try:
            # è¯»å–Markdownå†…å®¹
            with open(self.md_file, 'r', encoding='utf-8') as f:
                md_content = f.read()
            
            # è¯»å–ä¸­é—´ç»“æœJSONï¼ˆç”¨äºè·å–é¡µé¢ä¿¡æ¯ï¼‰
            page_info = self._get_page_info_from_json()
            
            # å¤„ç†Markdownå†…å®¹
            txt_content = self._process_markdown_to_txt(md_content, page_info)
            
            # ä¿å­˜TXTæ–‡ä»¶åˆ°txtç›®å½•
            txt_filename = f"{self.pdf_name}.txt"
            # ç¡®ä¿txtç›®å½•å­˜åœ¨
            txt_dir = Path("txt")
            txt_dir.mkdir(exist_ok=True)
            txt_path = txt_dir / txt_filename
            
            with open(txt_path, 'w', encoding='utf-8') as f:
                f.write(txt_content)
            
            print(f"ğŸ“„ TXTæ–‡ä»¶ç”Ÿæˆå®Œæˆ: {txt_filename}")
            return True
            
        except Exception as e:
            print(f"âŒ ç”ŸæˆTXTæ–‡ä»¶æ—¶å‡ºé”™: {e}")
            return False
    
    def _get_page_info_from_json(self) -> Dict:
        """ä»ä¸­é—´ç»“æœJSONä¸­è·å–é¡µé¢ä¿¡æ¯"""
        if not self.middle_json or not self.middle_json.exists():
            return {}
        
        try:
            with open(self.middle_json, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æå–é¡µé¢ä¿¡æ¯
            pdf_info = data.get('pdf_info', [])
            page_info = {}
            
            for page_data in pdf_info:
                page_idx = page_data.get('page_idx', 0)
                page_info[page_idx] = {
                    'page_num': page_idx + 1,
                    'blocks': page_data.get('para_blocks', [])
                }
            
            return page_info
            
        except Exception as e:
            print(f"âš ï¸  è¯»å–é¡µé¢ä¿¡æ¯æ—¶å‡ºé”™: {e}")
            return {}
    
    def _process_markdown_to_txt(self, md_content: str, page_info: Dict) -> str:
        """
        å¤„ç†Markdownå†…å®¹è½¬æ¢ä¸ºTXTæ ¼å¼
        
        Args:
            md_content: Markdownå†…å®¹
            page_info: é¡µé¢ä¿¡æ¯å­—å…¸
            
        Returns:
            str: å¤„ç†åçš„TXTå†…å®¹
        """
        # å»é™¤Markdownæ ¼å¼
        txt_content = self._remove_markdown_formatting(md_content)
        
        # å¦‚æœæœ‰é¡µé¢ä¿¡æ¯ï¼ŒæŒ‰é¡µé¢é‡æ–°ç»„ç»‡å†…å®¹
        if page_info:
            txt_content = self._reorganize_by_pages(txt_content, page_info)
        else:
            # å¦‚æœæ²¡æœ‰é¡µé¢ä¿¡æ¯ï¼Œä½¿ç”¨ç®€å•çš„é¡µé¢åˆ†å‰²
            txt_content = self._add_page_headers_simple(txt_content)
        
        return txt_content
    
    def _remove_markdown_formatting(self, md_content: str) -> str:
        """å»é™¤Markdownæ ¼å¼"""
        # å»é™¤æ ‡é¢˜çš„#å·
        content = re.sub(r'^#+\s*', '', md_content, flags=re.MULTILINE)
        
        # å»é™¤å…¶ä»–Markdownæ ¼å¼
        content = re.sub(r'\*\*(.*?)\*\*', r'\1', content)  # ç²—ä½“
        content = re.sub(r'\*(.*?)\*', r'\1', content)      # æ–œä½“
        content = re.sub(r'`(.*?)`', r'\1', content)        # ä»£ç 
        content = re.sub(r'\[(.*?)\]\(.*?\)', r'\1', content)  # é“¾æ¥
        
        return content
    
    def _reorganize_by_pages(self, content: str, page_info: Dict) -> str:
        """åŸºäºé¡µé¢ä¿¡æ¯é‡æ–°ç»„ç»‡å†…å®¹"""
        organized_content = []
        
        for page_idx in sorted(page_info.keys()):
            page_data = page_info[page_idx]
            page_num = page_data['page_num']
            
            # æ·»åŠ é¡µé¢å¤´éƒ¨ï¼ˆä¿®æ”¹æ ¼å¼ï¼šæ·»åŠ #å·å’Œæ–°çš„å›¾ç‰‡URLï¼‰
            page_image_url = f"http://9bn8of823990.vicp.fun:42712/images/{self.pdf_name}/page_images/{self.pdf_name}_page_{page_num}.png"
            page_header = f"#ï¼ˆ{self.pdf_name}ï¼‰ç¬¬{page_num}é¡µåŸå›¾å†…å®¹ï¼š{page_image_url}"
            
            organized_content.append(page_header)
            organized_content.append("&&é¡µé¢å†…å®¹...")  # æ·»åŠ &&æ ‡è®°
            organized_content.append("")  # ç©ºè¡Œ
            
            # è¿™é‡Œå¯ä»¥æ ¹æ®å®é™…çš„å—ä¿¡æ¯æ¥ç»„ç»‡å†…å®¹
            # æš‚æ—¶ä½¿ç”¨ç®€å•çš„æ–¹å¼
            organized_content.append(f"ç¬¬{page_num}é¡µå†…å®¹")
            organized_content.append("")
        
        return "\n".join(organized_content)
    
    def _add_page_headers_simple(self, content: str) -> str:
        """ç®€å•çš„é¡µé¢å¤´éƒ¨æ·»åŠ ï¼ˆå½“æ²¡æœ‰è¯¦ç»†é¡µé¢ä¿¡æ¯æ—¶ï¼‰"""
        lines = content.split('\n')
        processed_lines = []
        
        page_num = 1
        line_count = 0
        
        for line in lines:
            # æ¯50è¡Œä½œä¸ºä¸€é¡µï¼ˆå¯è°ƒæ•´ï¼‰
            if line_count % 50 == 0 and line_count > 0:
                page_num += 1
            
            # åœ¨æ¯é¡µå¼€å§‹æ·»åŠ é¡µé¢ä¿¡æ¯ï¼ˆä¿®æ”¹æ ¼å¼ï¼šæ·»åŠ #å·å’Œ&&ï¼‰
            if line_count % 50 == 0:
                page_image_url = f"page_images/{self.pdf_name}_page_{page_num}.png"
                page_header = f"#ï¼ˆ{self.pdf_name}ï¼‰ç¬¬{page_num}é¡µåŸå›¾å†…å®¹ï¼š{page_image_url}"
                processed_lines.append(page_header)
                processed_lines.append("&&é¡µé¢å†…å®¹...")  # æ·»åŠ &&æ ‡è®°
                processed_lines.append("")  # ç©ºè¡Œ
            
            processed_lines.append(line)
            line_count += 1
        
        return "\n".join(processed_lines)
    
    def process_all(self, pdf_path: str = None) -> bool:
        """
        æ‰§è¡Œæ‰€æœ‰å¢å¼ºå¤„ç†
        
        Args:
            pdf_path: PDFæ–‡ä»¶è·¯å¾„
            
        Returns:
            bool: æ˜¯å¦å…¨éƒ¨æˆåŠŸ
        """
        print(f"ğŸš€ å¼€å§‹å¤„ç†: {self.result_dir}")
        
        success_count = 0
        
        # ç”Ÿæˆé¡µé¢æˆªå›¾
        if self.generate_page_images(pdf_path):
            success_count += 1
        
        # ç”ŸæˆTXTæ–‡ä»¶
        if self.generate_txt_file():
            success_count += 1
        
        print(f"âœ¨ å¤„ç†å®Œæˆï¼æˆåŠŸ: {success_count}/2")
        return success_count == 2


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description="PDFå¤„ç†ç»“æœå¢å¼ºå·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # å¤„ç†å•ä¸ªç»“æœç›®å½•
  python post_process_enhancement.py /path/to/result/dir
  
  # å¤„ç†å•ä¸ªç»“æœç›®å½•å¹¶æŒ‡å®šPDFæ–‡ä»¶
  python post_process_enhancement.py /path/to/result/dir -p /path/to/original.pdf
  
  # æ‰¹é‡å¤„ç†è¾“å‡ºç›®å½•ä¸‹çš„æ‰€æœ‰ç»“æœ
  python post_process_enhancement.py /path/to/output --batch
        """
    )
    
    parser.add_argument(
        "result_path",
        help="å¤„ç†ç»“æœç›®å½•è·¯å¾„"
    )
    
    parser.add_argument(
        "-p", "--pdf",
        help="åŸå§‹PDFæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰"
    )
    
    parser.add_argument(
        "--batch",
        action="store_true",
        help="æ‰¹é‡å¤„ç†æ¨¡å¼"
    )
    
    args = parser.parse_args()
    
    result_path = Path(args.result_path)
    
    if not result_path.exists():
        print(f"âŒ è·¯å¾„ä¸å­˜åœ¨: {result_path}")
        return
    
    if args.batch:
        # æ‰¹é‡å¤„ç†æ¨¡å¼
        if not result_path.is_dir():
            print(f"âŒ æ‰¹é‡æ¨¡å¼éœ€è¦æä¾›ç›®å½•è·¯å¾„")
            return
        
        # æŸ¥æ‰¾æ‰€æœ‰å­ç›®å½•
        subdirs = [d for d in result_path.iterdir() if d.is_dir()]
        
        if not subdirs:
            print(f"âŒ æœªæ‰¾åˆ°ä»»ä½•å­ç›®å½•")
            return
        
        print(f"ğŸ”„ æ‰¹é‡å¤„ç†æ¨¡å¼ï¼Œæ‰¾åˆ° {len(subdirs)} ä¸ªç›®å½•")
        
        success_count = 0
        for subdir in subdirs:
            try:
                processor = PDFEnhancementProcessor(str(subdir))
                if processor.process_all(args.pdf):
                    success_count += 1
            except Exception as e:
                print(f"âŒ å¤„ç† {subdir} æ—¶å‡ºé”™: {e}")
        
        print(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼æˆåŠŸ: {success_count}/{len(subdirs)}")
    
    else:
        # å•ä¸ªå¤„ç†æ¨¡å¼
        try:
            processor = PDFEnhancementProcessor(str(result_path))
            processor.process_all(args.pdf)
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")


if __name__ == "__main__":
    main() 